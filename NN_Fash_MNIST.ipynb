{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e485dea-393a-46f4-a5f9-21591847969b",
   "metadata": {},
   "source": [
    "# Fashion MNIST classifier with Keras sequential API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a3ed0d4-25b0-4b47-9b56-8da8324e467a",
   "metadata": {},
   "source": [
    "### This code is part of Aurélien Géron Hands on Machine Learning... book with small changes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04a60b1e-0311-489c-95c0-5df6d321936c",
   "metadata": {},
   "source": [
    "### Import basic libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "373bfc43-9172-4ecf-9208-2cee7b08ebd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "assert len(physical_devices) > 0, \"Not enough GPU hardware devices available\"\n",
    "config = tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba8fc585-b16d-4f5b-b0c3-3b4e50b33343",
   "metadata": {},
   "source": [
    "### Get the dataset from keras.datasets and load into a variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "30fb2104-8cd6-461d-8b0f-ffcb73e724f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_mnist = keras.datasets.fashion_mnist\n",
    "(X_train_full, y_train_full), (X_test, y_test) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3437d350-b0ab-412d-aed7-b4085c183580",
   "metadata": {},
   "source": [
    "### Verify the size of the dataset and it's format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3b77f4e-33b2-4309-af47-022c781c6deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train_full.shape)\n",
    "print(X_train_full.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4ef91df-0017-4c47-a1b6-cb5684559a38",
   "metadata": {},
   "source": [
    "### Creating a validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c4613c61-01ef-4909-8b09-a61d8ff7a9cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid, X_train = X_train_full[:5000] / 255, X_train_full[5000:] / 255\n",
    "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ec69d30-00d4-40a2-ba5b-2f0f748d4e8d",
   "metadata": {},
   "source": [
    "### Check the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcbf3e4b-5b10-4046-abd3-453b3bd3de05",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"For training\")\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(\"For testing\")\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)\n",
    "print(\"For validation\")\n",
    "print(X_valid.shape)\n",
    "print(y_valid.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63946984-729a-4a91-9346-3b1f7f40250e",
   "metadata": {},
   "source": [
    "### Creating the classifier architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "53fa5162-dd41-4a74-af7b-85a8118822ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "model = Sequential()\n",
    "#model.add(keras.layers.InputLayer(input_shape=[28,28])) # Possible input layer  \n",
    "model.add(keras.layers.Flatten(input_shape=[28, 28])) # Converts the image into a unidimensional array\n",
    "model.add(keras.layers.Dense(300, activation=\"relu\"))\n",
    "model.add(keras.layers.Dense(100, activation=\"relu\"))\n",
    "model.add(keras.layers.Dense(10, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a576e48f-9732-482b-995f-53529e41ef3d",
   "metadata": {},
   "source": [
    "### Printing the model summary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59558251-8e40-402d-9f85-2c469eda0d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28779564-a981-42a9-8312-b8b20ae43142",
   "metadata": {},
   "source": [
    "### Plot of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea216d9-b512-4348-8717-bf6e5930506d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pydot\n",
    "#import graphviz\n",
    "keras.utils.plot_model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2905678c-c0a2-406a-b6ed-d95fa6943810",
   "metadata": {},
   "source": [
    "### Visualizing some setail of the layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "260c2cfe-014f-4088-9a49-9d43ccb5547c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.layers)\n",
    "hidden3 = model.layers[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c30d473e-1085-47cc-9fac-6824376e9265",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights, biases = hidden1.get_weights() # Note the random weights to break the simetry and help the backpropagation\n",
    "print(\"Weights.shape:\")\n",
    "print(weights.shape)\n",
    "print(\"Weights values:\")\n",
    "print(weights)\n",
    "print(\"Biases.shape:\")\n",
    "print(biases.shape)\n",
    "print(\"Weights values:\")\n",
    "print(biases)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60be0994-28db-45da-8932-bc163ba30cff",
   "metadata": {},
   "source": [
    "### Compiling the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "90aab312-ca9d-40d7-be1b-c57f2fd9fa35",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "             optimizer=\"sgd\", # sgd=stochastic gradient descent\n",
    "             metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "204afc1d-ed66-4a7e-bfd0-37df457df2f5",
   "metadata": {},
   "source": [
    "### Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "053b9047-7f2d-424b-845b-96fedd39e1be",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train, y_train, epochs=30,\n",
    "                   validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a929234-7d06-4420-aac7-0414ff4a74a8",
   "metadata": {},
   "source": [
    "### Visualizing the learning curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ef7f18-a3eb-46ac-8894-5dcbceb0461c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.DataFrame(history.history).plot(figsize=(12,8))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0, 1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f23f840-359f-4309-8e09-183277cdb468",
   "metadata": {},
   "source": [
    "### Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68812caa-0514-4cff-84c4-a3c94d696491",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "727ef4f3-0424-4c31-916d-746c4b459086",
   "metadata": {},
   "source": [
    "### Using the model to make new predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecd59401-1d5a-43e3-a8a1-1d4bb6125a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new = X_test[:3]\n",
    "y_proba = model.predict(X_new)\n",
    "y_proba.round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89c1add5-11be-4627-99ec-52e53dd444c7",
   "metadata": {},
   "source": [
    "### Testing Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1535db11-3531-4131-9d5e-9d6bd16a8d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "root_logdir = os.path.join(os.curdir, \"my_logs\")\n",
    "def get_run_logdir():\n",
    "    import time\n",
    "    run_id = time.strftime(\"run_%Y_%m_%d-%H_%M_%S\")\n",
    "    return os.path.join(root_logdir, run_id)\n",
    "\n",
    "run_logdir = get_run_logdir()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29bb6dbf-09d5-437e-923f-45596fc8b32d",
   "metadata": {},
   "source": [
    "### Repeating the code ultil the .fit method point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d472521-4920-44c5-9c93-869b2a9ebb55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "assert len(physical_devices) > 0, \"Not enough GPU hardware devices available\"\n",
    "config = tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "\n",
    "fashion_mnist = keras.datasets.fashion_mnist\n",
    "(X_train_full, y_train_full), (X_test, y_test) = fashion_mnist.load_data()\n",
    "\n",
    "print(X_train_full.shape)\n",
    "print(X_train_full.dtype)\n",
    "\n",
    "X_valid, X_train = X_train_full[:5000] / 255, X_train_full[5000:] / 255\n",
    "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "model = Sequential()\n",
    "#model.add(keras.layers.InputLayer(input_shape=[28,28])) # Possible input layer  \n",
    "model.add(keras.layers.Flatten(input_shape=[28, 28])) # Converts the image into a unidimensional array\n",
    "model.add(keras.layers.Dense(300, activation=\"relu\"))\n",
    "model.add(keras.layers.Dense(100, activation=\"relu\"))\n",
    "model.add(keras.layers.Dense(10, activation=\"softmax\"))\n",
    "\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "             optimizer=\"sgd\", # sgd=stochastic gradient descent\n",
    "             metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d93b6375-b0fb-457a-a13f-2df4d7c72555",
   "metadata": {},
   "source": [
    "### Calling .fit with the Tensorboard Callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b77df8b4-3659-4c5a-9c62-350907f31f87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.7139 - accuracy: 0.7688 - val_loss: 0.5103 - val_accuracy: 0.8230\n",
      "Epoch 2/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.4837 - accuracy: 0.8312 - val_loss: 0.4506 - val_accuracy: 0.8466\n",
      "Epoch 3/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.4370 - accuracy: 0.8489 - val_loss: 0.4242 - val_accuracy: 0.8556\n",
      "Epoch 4/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.4108 - accuracy: 0.8569 - val_loss: 0.4045 - val_accuracy: 0.8610\n",
      "Epoch 5/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.3919 - accuracy: 0.8623 - val_loss: 0.3833 - val_accuracy: 0.8696\n",
      "Epoch 6/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.3756 - accuracy: 0.8675 - val_loss: 0.3705 - val_accuracy: 0.8700\n",
      "Epoch 7/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.3633 - accuracy: 0.8721 - val_loss: 0.3875 - val_accuracy: 0.8610\n",
      "Epoch 8/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.3518 - accuracy: 0.8755 - val_loss: 0.3501 - val_accuracy: 0.8812\n",
      "Epoch 9/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.3422 - accuracy: 0.8775 - val_loss: 0.3449 - val_accuracy: 0.8806\n",
      "Epoch 10/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.3340 - accuracy: 0.8817 - val_loss: 0.3471 - val_accuracy: 0.8756\n",
      "Epoch 11/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.3253 - accuracy: 0.8837 - val_loss: 0.3341 - val_accuracy: 0.8848\n",
      "Epoch 12/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.3177 - accuracy: 0.8863 - val_loss: 0.3384 - val_accuracy: 0.8786\n",
      "Epoch 13/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.3102 - accuracy: 0.8883 - val_loss: 0.3479 - val_accuracy: 0.8760\n",
      "Epoch 14/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.3036 - accuracy: 0.8906 - val_loss: 0.3335 - val_accuracy: 0.8806\n",
      "Epoch 15/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2969 - accuracy: 0.8934 - val_loss: 0.3295 - val_accuracy: 0.8868\n",
      "Epoch 16/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2920 - accuracy: 0.8945 - val_loss: 0.3256 - val_accuracy: 0.8842\n",
      "Epoch 17/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2868 - accuracy: 0.8967 - val_loss: 0.3164 - val_accuracy: 0.8892\n",
      "Epoch 18/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2819 - accuracy: 0.8981 - val_loss: 0.3178 - val_accuracy: 0.8886\n",
      "Epoch 19/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2757 - accuracy: 0.9004 - val_loss: 0.3200 - val_accuracy: 0.8868\n",
      "Epoch 20/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2712 - accuracy: 0.9026 - val_loss: 0.3139 - val_accuracy: 0.8856\n",
      "Epoch 21/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2663 - accuracy: 0.9046 - val_loss: 0.3070 - val_accuracy: 0.8890\n",
      "Epoch 22/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2621 - accuracy: 0.9053 - val_loss: 0.3049 - val_accuracy: 0.8910\n",
      "Epoch 23/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2577 - accuracy: 0.9067 - val_loss: 0.3138 - val_accuracy: 0.8840\n",
      "Epoch 24/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2528 - accuracy: 0.9086 - val_loss: 0.3063 - val_accuracy: 0.8914\n",
      "Epoch 25/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2484 - accuracy: 0.9101 - val_loss: 0.3010 - val_accuracy: 0.8916\n",
      "Epoch 26/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2439 - accuracy: 0.9128 - val_loss: 0.3284 - val_accuracy: 0.8800\n",
      "Epoch 27/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2410 - accuracy: 0.9135 - val_loss: 0.2989 - val_accuracy: 0.8928\n",
      "Epoch 28/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2371 - accuracy: 0.9146 - val_loss: 0.2963 - val_accuracy: 0.8922\n",
      "Epoch 29/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2332 - accuracy: 0.9155 - val_loss: 0.3185 - val_accuracy: 0.8842\n",
      "Epoch 30/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2303 - accuracy: 0.9172 - val_loss: 0.3160 - val_accuracy: 0.8850\n"
     ]
    }
   ],
   "source": [
    "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)\n",
    "history = model.fit(X_train, y_train, epochs=30,\n",
    "validation_data=(X_valid, y_valid),\n",
    "callbacks=[tensorboard_cb])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaa8eab2-786b-4477-bc0b-4610a5cd9ffe",
   "metadata": {},
   "source": [
    "### Visualizing the data in Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8cf80e7b-e269-4d8d-bf57-0fb1ccdffc78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 7775), started 0:07:23 ago. (Use '!kill 7775' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-d86b8af9a0a7218a\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-d86b8af9a0a7218a\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          url.port = 6006;\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir=./my_logs --port=6006"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "169be083-4c26-4731-94f2-76994569c60b",
   "metadata": {},
   "source": [
    "### More advanced features from Tensorboard, check the other tabs after running:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b366a2d7-eefe-451e-8b66-4403e58790ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "test_logdir = get_run_logdir()\n",
    "writer = tf.summary.create_file_writer(test_logdir)\n",
    "with writer.as_default():\n",
    "    for step in range(1, 1000 + 1):\n",
    "        tf.summary.scalar(\"my_scalar\", np.sin(step / 10), step=step)\n",
    "        data = (np.random.randn(100) + 2) * step / 100 # some random data\n",
    "        tf.summary.histogram(\"my_hist\", data, buckets=50, step=step)\n",
    "        images = np.random.rand(2, 32, 32, 3) # random 32×32 RGB images\n",
    "        tf.summary.image(\"my_images\", images * step / 1000, step=step)\n",
    "        texts = [\"The step is \" + str(step), \"Its square is \" + str(step**2)]\n",
    "        tf.summary.text(\"my_text\", texts, step=step)\n",
    "        sine_wave = tf.math.sin(tf.range(12000) / 48000 * 2 * np.pi * step)\n",
    "        audio = tf.reshape(tf.cast(sine_wave, tf.float32), [1, -1, 1])\n",
    "        tf.summary.audio(\"my_audio\", audio, sample_rate=48000, step=step)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
